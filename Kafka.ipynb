{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Streaming with Kafka\n",
    "\n",
    "## Overview \n",
    "\n",
    "### What you'll learn\n",
    "\n",
    "In this section, you will learn: \n",
    "\n",
    "1. What Kafka is\n",
    "2. How to stream data from one process to another\n",
    "\n",
    "### Prerequisites\n",
    "Before starting this section, you should have an understanding of: \n",
    "\n",
    "1. Basic python\n",
    "\n",
    "### Introduction\n",
    "\n",
    "#### What is Kafka?\n",
    "\n",
    "Kafka is a **big data streaming service** that allows multiple sources to upload and download data, such as log files or bug reports. Kafka organizes data and ensures that it is kept in order, and that all data goes where it needs to. Kafka was originally created by LinkedIn, but is now maintained by Apache.\n",
    "\n",
    "## Kafka Concepts\n",
    "\n",
    "### Messages\n",
    "\n",
    "Kafka transmits data in the form of **messages**, which are small files containing any type of data. Messages are created and transmitted in real-time, and some examples of messages include:\n",
    "- program crash logs\n",
    "- customer support chat records\n",
    "- forms received through a webpage\n",
    "\n",
    "These messages are given to Kafka via API calls. Once a message is given to Kafka, the data is queued and stored in servers until users access the messages\n",
    "\n",
    "### Producers and Consumers\n",
    "\n",
    "Programs or users that create and send data are called **producers**, and programs or users that read data are called **consumers**. There are separate APIs for [producers](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaProducer.html) and [consumers](https://kafka-python.readthedocs.io/en/master/apidoc/KafkaConsumer.html), and you can find examples of how to use them [here](https://kafka-python.readthedocs.io/en/master/usage.html).\n",
    "\n",
    "### Kafka Topics\n",
    "\n",
    "Producers and consumers subscribe to Kafka topics, which are the structure Kafka uses for **data organization**. A topic is a group of related data that is separated into its own sub-stream. Organizations can pick and choose who has access to which topics, which allows companies to keep data secure by limiting the number of people who have access to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Simple Kafka Program\n",
    "\n",
    "### Setup\n",
    "#### Install Zookeeper and Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://apache-mirror.8birdsvideo.com/zookeeper/zookeeper-3.5.5/apache-zookeeper-3.5.5-bin.tar.gz\n",
    "!tar -xzf apache-zookeeper-3.5.5-bin.tar.gz\n",
    "!wget http://www-us.apache.org/dist/kafka/2.3.0/kafka_2.12-2.3.0.tgz\n",
    "!tar -xzf kafka_2.12-2.3.0.tgz\n",
    "!rm *.gz *.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Zookeeper and Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/zookeeper-server-start.sh -daemon kafka_2.12-2.3.0/config/zookeeper.properties\n",
    "!kafka_2.12-2.3.0/bin/kafka-server-start.sh -daemon kafka_2.12-2.3.0/config/server.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create New Kafka Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic MyHackBUTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Topic Was Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kafka_2.12-2.3.0/bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the Kafka Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a (very simple) Kafka Producer/Consumer\n",
    "\n",
    "The below example is an extremely simple example of a Kafka Producer/Consumer setup. Unfortunately, due to limitations with Google Colab, we cannot run these in parallel. In a normal environment, this would be split into two files, with producer.py and consumer.py running in parallel.\n",
    "\n",
    "As the producer pushes data to the topic, every consumer that's observing the topic will pull the data in real time. The producer and consumers don't even need to be on the same computer - in fact, they usually aren't. This allows us to efficiently stream data in real-time from one point to another. This can be used for all sorts of applications including chat services and real-time social media analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kafka\n",
    "import json\n",
    "\n",
    "# producer.py\n",
    "producer = kafka.KafkaProducer(bootstrap_servers=['localhost:9092'],\n",
    "                         value_serializer=lambda x: \n",
    "                         json.dumps(x).encode('utf-8'))\n",
    "\n",
    "for e in range(10):\n",
    "    data = {'number' : e}\n",
    "    producer.send('MyHackBUTopic', value=data)\n",
    "\n",
    "\n",
    "# consumer.py\n",
    "consumer = kafka.KafkaConsumer(\n",
    "    'MyHackBUTopic',\n",
    "     bootstrap_servers=['localhost:9092'],\n",
    "     auto_offset_reset='earliest',\n",
    "     enable_auto_commit=True,\n",
    "     group_id='my-group',\n",
    "     value_deserializer=lambda x: json.loads(x.decode('utf-8')))\n",
    "\n",
    "for message in consumer:\n",
    "    message = message.value\n",
    "    print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
